{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "def explore_pickle_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and explore the structure of a pickle file\n",
    "    \"\"\"\n",
    "    # Load pickle file\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Get all top-level keys\n",
    "    print(\"\\n=== Top Level Keys ===\")\n",
    "    print(\"-\" * 40)\n",
    "    for key in sorted(data.keys()):\n",
    "        value = data[key]\n",
    "        value_type = type(value).__name__\n",
    "        \n",
    "        # For simple types, show the value\n",
    "        if isinstance(value, (str, int, float, bool)) or value is None:\n",
    "            print(f\"{key}: {value_type} = {value}\")\n",
    "        # For collections, show the type and size\n",
    "        elif isinstance(value, dict):\n",
    "            print(f\"{key}: {value_type} with {len(value)} items\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"{key}: {value_type} with {len(value)} elements\")\n",
    "        else:\n",
    "            print(f\"{key}: {value_type}\")\n",
    "    \n",
    "    # Show a sample of nested data structures\n",
    "    if 'data' in data:\n",
    "        print(\"\\n=== Data Field Structure ===\")\n",
    "        print(\"-\" * 40)\n",
    "        pprint(list(data['data'].keys()))\n",
    "    \n",
    "    if 'salesRanks' in data:\n",
    "        print(\"\\n=== Sales Ranks Categories ===\")\n",
    "        print(\"-\" * 40)\n",
    "        pprint(list(data['salesRanks'].keys()))\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup path - adjust this to your data location\n",
    "    base_path = Path('/Users/takedownccp/Documents/Cursor/DDU/data')\n",
    "    # pickle_files = list((base_path / 'raw_data').glob('*_raw.pkl'))\n",
    "    # pickle_files = ['B0CHTZ6NCL_raw.pkl', 'B07N52NLC3_raw.pkl', 'B09MZ9T3KT_raw.pkl', 'B09MZBXNHP_raw.pkl', 'B09QL5K6LW_raw.pkl', 'B09ZLSR8PH_raw.pkl']\n",
    "    \n",
    "    pickle_files = ['B0CHTZ6NCL_raw.pkl']\n",
    "    if pickle_files:\n",
    "        # Load the first pickle file\n",
    "        first_file = (base_path / 'raw_data' / pickle_files[0])\n",
    "        print(f\"Exploring file: {first_file.name}\")\n",
    "        explore_pickle_data(first_file)\n",
    "    else:\n",
    "        print(\"No pickle files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from \"Data\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing B0CHTZ6NCL_raw.pkl\n",
      "Saved individual file for B0CHTZ6NCL\n",
      "\n",
      "Statistics for B0CHTZ6NCL:\n",
      "Time range: 2023-09-26 10:16:00-04:00 to 2025-01-13 08:52:00-05:00\n",
      "Number of records: 4168\n",
      "Available metrics: ['AMAZON', 'NEW', 'USED', 'NEW_FBA', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'COUNT_REVIEWS', 'RATING']\n",
      "\n",
      "Processing B07N52NLC3_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:68: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:68: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:68: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved individual file for B07N52NLC3\n",
      "\n",
      "Statistics for B07N52NLC3:\n",
      "Time range: 2019-06-20 16:28:00-04:00 to 2025-01-12 14:28:00-05:00\n",
      "Number of records: 15374\n",
      "Available metrics: ['AMAZON', 'NEW', 'USED', 'SALES', 'LISTPRICE', 'COUNT_NEW', 'NEW_FBA', 'BUY_BOX_SHIPPING', 'COUNT_REVIEWS', 'RATING']\n",
      "\n",
      "Processing B09MZ9T3KT_raw.pkl\n",
      "Saved individual file for B09MZ9T3KT\n",
      "\n",
      "Statistics for B09MZ9T3KT:\n",
      "Time range: 2021-12-09 23:36:00-05:00 to 2025-01-13 03:32:00-05:00\n",
      "Number of records: 7476\n",
      "Available metrics: ['AMAZON', 'NEW', 'USED', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'COUNT_REVIEWS', 'RATING', 'NEW_FBA']\n",
      "\n",
      "Processing B09MZBXNHP_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:68: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:68: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved individual file for B09MZBXNHP\n",
      "\n",
      "Statistics for B09MZBXNHP:\n",
      "Time range: 2021-12-10 05:48:00-05:00 to 2025-01-12 13:34:00-05:00\n",
      "Number of records: 6481\n",
      "Available metrics: ['AMAZON', 'NEW', 'USED', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'COUNT_REVIEWS', 'NEW_FBA', 'RATING']\n",
      "\n",
      "Processing B09QL5K6LW_raw.pkl\n",
      "Saved individual file for B09QL5K6LW\n",
      "\n",
      "Statistics for B09QL5K6LW:\n",
      "Time range: 2022-02-21 14:28:00-05:00 to 2025-01-11 15:16:00-05:00\n",
      "Number of records: 7289\n",
      "Available metrics: ['AMAZON', 'NEW', 'USED', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'NEW_FBA', 'COUNT_REVIEWS', 'RATING']\n",
      "\n",
      "Processing B09ZLSR8PH_raw.pkl\n",
      "Saved individual file for B09ZLSR8PH\n",
      "\n",
      "Statistics for B09ZLSR8PH:\n",
      "Time range: 2022-05-05 14:08:00-04:00 to 2025-01-10 08:48:00-05:00\n",
      "Number of records: 9237\n",
      "Available metrics: ['AMAZON', 'NEW', 'USED', 'RATING', 'COUNT_REVIEWS', 'SALES', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'LISTPRICE', 'NEW_FBA']\n",
      "\n",
      "=== Summary Report ===\n",
      "\n",
      "ASIN: B0CHTZ6NCL\n",
      "Records: 4168\n",
      "Time range: 2023-09-26 10:16:00-04:00 to 2025-01-13 08:52:00-05:00\n",
      "Columns: ['AMAZON', 'NEW', 'USED', 'NEW_FBA', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'COUNT_REVIEWS', 'RATING']\n",
      "--------------------------------------------------\n",
      "\n",
      "ASIN: B07N52NLC3\n",
      "Records: 15374\n",
      "Time range: 2019-06-20 16:28:00-04:00 to 2025-01-12 14:28:00-05:00\n",
      "Columns: ['AMAZON', 'NEW', 'USED', 'SALES', 'LISTPRICE', 'COUNT_NEW', 'NEW_FBA', 'BUY_BOX_SHIPPING', 'COUNT_REVIEWS', 'RATING']\n",
      "--------------------------------------------------\n",
      "\n",
      "ASIN: B09MZ9T3KT\n",
      "Records: 7476\n",
      "Time range: 2021-12-09 23:36:00-05:00 to 2025-01-13 03:32:00-05:00\n",
      "Columns: ['AMAZON', 'NEW', 'USED', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'COUNT_REVIEWS', 'RATING', 'NEW_FBA']\n",
      "--------------------------------------------------\n",
      "\n",
      "ASIN: B09MZBXNHP\n",
      "Records: 6481\n",
      "Time range: 2021-12-10 05:48:00-05:00 to 2025-01-12 13:34:00-05:00\n",
      "Columns: ['AMAZON', 'NEW', 'USED', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'COUNT_REVIEWS', 'NEW_FBA', 'RATING']\n",
      "--------------------------------------------------\n",
      "\n",
      "ASIN: B09QL5K6LW\n",
      "Records: 7289\n",
      "Time range: 2022-02-21 14:28:00-05:00 to 2025-01-11 15:16:00-05:00\n",
      "Columns: ['AMAZON', 'NEW', 'USED', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'SALES', 'LISTPRICE', 'NEW_FBA', 'COUNT_REVIEWS', 'RATING']\n",
      "--------------------------------------------------\n",
      "\n",
      "ASIN: B09ZLSR8PH\n",
      "Records: 9237\n",
      "Time range: 2022-05-05 14:08:00-04:00 to 2025-01-10 08:48:00-05:00\n",
      "Columns: ['AMAZON', 'NEW', 'USED', 'RATING', 'COUNT_REVIEWS', 'SALES', 'COUNT_NEW', 'BUY_BOX_SHIPPING', 'LISTPRICE', 'NEW_FBA']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "/var/folders/mv/mgw8yk512lz4vn9tx8g6pnrm0000gn/T/ipykernel_9684/751893373.py:68: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "\n",
    "def keepa_to_est(keepa_time):\n",
    "    \"\"\"Convert Keepa time to EST datetime\"\"\"\n",
    "    if isinstance(keepa_time, datetime):\n",
    "        if keepa_time.tzinfo is None:\n",
    "            keepa_time = pytz.UTC.localize(keepa_time)\n",
    "        return keepa_time.astimezone(pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    try:\n",
    "        unix_time = (keepa_time + 21564000) * 60\n",
    "        utc_time = datetime.fromtimestamp(unix_time, tz=pytz.UTC)\n",
    "        return utc_time.astimezone(pytz.timezone('US/Eastern'))\n",
    "    except TypeError as e:\n",
    "        print(f\"Error converting time: {keepa_time}, type: {type(keepa_time)}\")\n",
    "        raise e\n",
    "\n",
    "def process_data_to_timeseries(file_path):\n",
    "    \"\"\"Convert nested data structure to time series DataFrame\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    nested_data = data.get('data', {})\n",
    "    asin = data.get('asin', 'unknown')  # Get ASIN for identification\n",
    "    time_series_dict = {}\n",
    "    \n",
    "    metrics = {\n",
    "        'AMAZON': ['AMAZON_time', 'AMAZON'],\n",
    "        'NEW': ['NEW_time', 'NEW'],\n",
    "        'USED': ['USED_time', 'USED'],\n",
    "        'SALES': ['SALES_time', 'SALES'],\n",
    "        'LISTPRICE': ['LISTPRICE_time', 'LISTPRICE'],\n",
    "        'NEW_FBA': ['NEW_FBA_time', 'NEW_FBA'],\n",
    "        'COUNT_NEW': ['COUNT_NEW_time', 'COUNT_NEW'],\n",
    "        'RATING': ['RATING_time', 'RATING'],\n",
    "        'COUNT_REVIEWS': ['COUNT_REVIEWS_time', 'COUNT_REVIEWS'],\n",
    "        'BUY_BOX_SHIPPING': ['BUY_BOX_SHIPPING_time', 'BUY_BOX_SHIPPING']\n",
    "    }\n",
    "    \n",
    "    for metric_name, (time_key, value_key) in metrics.items():\n",
    "        if time_key in nested_data and value_key in nested_data:\n",
    "            times = nested_data[time_key]\n",
    "            values = nested_data[value_key]\n",
    "            \n",
    "            if not isinstance(times, (list, np.ndarray)) or not isinstance(values, (list, np.ndarray)):\n",
    "                continue\n",
    "                \n",
    "            for t, v in zip(times, values):\n",
    "                try:\n",
    "                    est_time = keepa_to_est(t)\n",
    "                    \n",
    "                    if est_time not in time_series_dict:\n",
    "                        time_series_dict[est_time] = {}\n",
    "                    \n",
    "                    time_series_dict[est_time][metric_name] = np.nan if v == -1 else v\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {metric_name} for {asin}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(time_series_dict, orient='index')\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df.fillna(method='ffill')\n",
    "    df = df.fillna(method='bfill')\n",
    "    \n",
    "    return df, asin\n",
    "\n",
    "def process_multiple_files(pickle_files, base_path):\n",
    "    \"\"\"Process multiple pickle files and save their time series data\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for pickle_file in pickle_files:\n",
    "        print(f\"\\nProcessing {pickle_file}\")\n",
    "        file_path = base_path / 'raw_data' / pickle_file\n",
    "        \n",
    "        try:\n",
    "            df, asin = process_data_to_timeseries(file_path)\n",
    "            results[asin] = df\n",
    "            \n",
    "            # Save individual file\n",
    "            output_path = base_path / 'processed_data' / f'{asin}_timeseries.csv'\n",
    "            df.to_csv(output_path)\n",
    "            print(f\"Saved individual file for {asin}\")\n",
    "            \n",
    "            # Print basic statistics\n",
    "            print(f\"\\nStatistics for {asin}:\")\n",
    "            print(f\"Time range: {df.index.min()} to {df.index.max()}\")\n",
    "            print(f\"Number of records: {len(df)}\")\n",
    "            print(\"Available metrics:\", list(df.columns))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pickle_file}: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup path\n",
    "    base_path = Path('/Users/takedownccp/Documents/Cursor/DDU/data')\n",
    "    \n",
    "    # List of files to process\n",
    "    pickle_files = [\n",
    "        'B0CHTZ6NCL_raw.pkl', \n",
    "        'B07N52NLC3_raw.pkl', \n",
    "        'B09MZ9T3KT_raw.pkl', \n",
    "        'B09MZBXNHP_raw.pkl', \n",
    "        'B09QL5K6LW_raw.pkl', \n",
    "        'B09ZLSR8PH_raw.pkl'\n",
    "    ]\n",
    "    \n",
    "    # Process all files\n",
    "    results = process_multiple_files(pickle_files, base_path)\n",
    "    \n",
    "    # Optional: Create a combined report\n",
    "    print(\"\\n=== Summary Report ===\")\n",
    "    for asin, df in results.items():\n",
    "        print(f\"\\nASIN: {asin}\")\n",
    "        print(f\"Records: {len(df)}\")\n",
    "        print(f\"Time range: {df.index.min()} to {df.index.max()}\")\n",
    "        print(\"Columns:\", list(df.columns))\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Optional: Save a combined dataset\n",
    "    # Uncomment if you want to combine all data into one file\n",
    "    \"\"\"\n",
    "    combined_df = pd.concat(results.values(), keys=results.keys(), names=['ASIN', 'Date'])\n",
    "    combined_output_path = base_path / 'processed_data' / 'combined_timeseries.csv'\n",
    "    combined_df.to_csv(combined_output_path)\n",
    "    print(f\"\\nSaved combined dataset to {combined_output_path}\")\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
